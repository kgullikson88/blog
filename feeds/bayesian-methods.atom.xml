<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Adventures of the Datastronomer</title><link href="http://kgullikson88.github.io/blog/" rel="alternate"></link><link href="http://kgullikson88.github.io/blog/feeds/bayesian-methods.atom.xml" rel="self"></link><id>http://kgullikson88.github.io/blog/</id><updated>2015-07-06T05:00:00-05:00</updated><entry><title>On Bayesian Model Comparison and Climate Change</title><link href="http://kgullikson88.github.io/blog/climate-change.html" rel="alternate"></link><updated>2015-07-06T05:00:00-05:00</updated><author><name>Kevin Gullikson</name></author><id>tag:kgullikson88.github.io,2015-07-06:blog/climate-change.html</id><summary type="html">&lt;h2&gt;Or: Is there really a pause in global warming?&lt;/h2&gt;
&lt;p&gt;A common criticism made by climate change skeptics is that there has not been any warming in the last several years. They claim that since the CO&lt;span class="math"&gt;\(_2\)&lt;/span&gt; abundance is still increasing, the lack of increasing temperatures proves that CO&lt;span class="math"&gt;\(_2\)&lt;/span&gt; &lt;em&gt;cannot&lt;/em&gt; be driving the temperature change.&lt;/p&gt;
&lt;p&gt;Let's take a look at the data. For this project, I will be using the &lt;a href="http://berkeleyearth.org/data/"&gt;Berkeley Earth compilation&lt;/a&gt; of global average surface temperatures and ocean temperatures. The data go back to 1880 and, unlike other compilations I have found, include an uncertainty in the temperature anomaly as well as just the value. The data from the &lt;a href="http://data.giss.nasa.gov/gistemp/"&gt;Goddard Institute for Space Studies&lt;/a&gt;, which is more commonly used but does not include uncertainties, is almost identical to the values I use.&lt;/p&gt;
&lt;p&gt;Here is the last 15 years.&lt;/p&gt;
&lt;style type="text/css"&gt;
  .centeredImage
    {
    text-align:center;
    margin-top:0px;
    margin-bottom:0px;
    padding:0px;
    }
&lt;/style&gt;

&lt;p class="centeredImage"&gt;&lt;img src=Figures/Anomaly_Recent.png&gt;&lt;/p&gt;

&lt;p&gt;Indeed, there is really not much warming, and it certainly appears to be constant. But only looking at the last 15 years is silly! Here is the data since 1880, which is as far back as the temperature estimates go. In the full data, I am showing the uncertainty in the temperature anomaly in each year with a colored band. Basically, any temperature anomaly that falls within the band is consistent with the measurements we have.&lt;/p&gt;
&lt;p class="centeredImage"&gt;&lt;img src=Figures/Anomaly_Full.png&gt;&lt;/p&gt;

&lt;p&gt;This data shows a few things really clearly.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The global average temperatures have &lt;em&gt;definitely&lt;/em&gt; increased since 1900 or so.&lt;/li&gt;
&lt;li&gt;The values are high correlated. What I mean by that is that temperatures in a given year are related to temperatures in previous years. The most obvious example of that is the plateau from about 1940-1970, which was &lt;a href="http://www.newscientist.com/article/dn11639-climate-myths-the-cooling-after-1940-shows-co2-does-not-cause-warming.html#.VZlUi63InK4"&gt;likely caused&lt;/a&gt; by increased aerosols from industrial activity and volcano eruptions.&lt;/li&gt;
&lt;li&gt;The apparent turnover at recent times is dubious, precisely because of the correlated temperatures.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The rest of this post will focus on leveraging some heavy statistical machinery on the last point to answer the following question:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; "Does the data support the hypothesis that temperatures have stopped increasing in the last 1-2 decades?" &lt;/strong&gt;&lt;/p&gt;
&lt;h1&gt;Bayesian Model Selection&lt;/h1&gt;
&lt;p&gt;If you don't want to get into too much math, just skip to "The Models" now. If you want some details on bayesian model selection, then read on. The statistical machinery I will use here is bayesian model selection. It centers on Bayes' equation:&lt;/p&gt;
&lt;div class="math"&gt;$$
P(\theta|D, M) = \frac{P(D|\theta, M) P(\theta|M)}{P(D|M)}
$$&lt;/div&gt;
&lt;p&gt;In words, Bayes' equation says that the probability of a set of model parameters (&lt;span class="math"&gt;\(\theta\)&lt;/span&gt;), given the data we have (D) and the model we choose (M), is equal to the probability of the data given the parameters and the model, times the probability of the parameters, and divided by the probability of the data under the model. The individual terms in Bayes' equation are:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt; Posterior Probability Function: &lt;span class="math"&gt;\(P(\theta|D, M)\)&lt;/span&gt; &lt;/li&gt;
  &lt;li&gt; Likelihood Function: &lt;span class="math"&gt;\(P(D|\theta, M)\)&lt;/span&gt; &lt;/li&gt;
  &lt;li&gt; Prior Probability: &lt;span class="math"&gt;\(P(\theta|M)\)&lt;/span&gt; &lt;/li&gt;
  &lt;li&gt; Bayesian Evidence: &lt;span class="math"&gt;\(P(D|M)\)&lt;/span&gt; &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The likelihood function is a measure of how far away the value predicted by the model is from the data. Model parameters that predict the value far from what it actually is have low probability while parameters that predict values close to the data have high probability. A typical function for this is the gaussian likelihood that compares each data point (&lt;span class="math"&gt;\(x_i, y_i, \sigma_i\)&lt;/span&gt;) to what the model predicts:&lt;/p&gt;
&lt;div class="math"&gt;$$
P(D|\theta, M) = \prod_i \frac{1}{\sqrt{2\pi\sigma_i^2}} e^{-0.5(y_i - M(x_i, \theta))^2 / \sigma_i^2}
$$&lt;/div&gt;
&lt;p&gt;The prior probability function uses information we already have to adjust the probability of the given model parameters. I could do whole posts about the prior function, and other people have, but for this project I will exclusively use flat, uninformative priors.&lt;/p&gt;
&lt;p&gt;In many applications where we only care about the best parameter values, the bayesian evidence is completely ignored since it is a constant for a given dataset and model, and is difficult to calculate. However, it is very important for choosing which model best describes the data so I will focus on it a bit more. Here is the evidence in its full glory:&lt;/p&gt;
&lt;div class="math"&gt;$$
P(D|M) = \int P(D|\theta, M)P(\theta|M)d^N\theta
$$&lt;/div&gt;
&lt;p&gt;Basically, the bayesian evidence is a weighted sum of the likelihood function over the entire possible parameter space. The nice thing is that it mathematically implements &lt;a href="https://en.wikipedia.org/wiki/Occam's_razor"&gt;Occam's razor&lt;/a&gt; since models with more parameters but equal predictive capability will have a larger parameter space, which means a lot more space with low likelihood, and so the evidence decreases. However, adding parameters that significantly improve the predictive capability of the model will &lt;em&gt;increase&lt;/em&gt; the evidence even though the parameter space increases. This is exactly why bayesian evidence is used to determine which model best describes the data, and is why I will be using it here. &lt;/p&gt;
&lt;h1&gt;The Models&lt;/h1&gt;
&lt;p&gt;I will try out four different models for the data and compare the bayesian evidence for each.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A constant model with one parameter (&lt;span class="math"&gt;\(\Delta T_0\)&lt;/span&gt;).&lt;/li&gt;
&lt;li&gt;A fifth-order polynomial given by &lt;span class="math"&gt;\(\Delta T = c_0 + c_1t + c_2t^2 + c_3t^3 + c_4t^4 + c_5t^5\)&lt;/span&gt; with parameters &lt;span class="math"&gt;\(\theta_{M_2} = c_0, c_1, c_2, c_3, c_4, c_5\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;An exponential growth model given by &lt;span class="math"&gt;\(\Delta T = \Delta T_0 + e^{f(t-t_0)}\)&lt;/span&gt; with parameters &lt;span class="math"&gt;\(\theta_{M3} = \Delta T_0, f, t_0\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;An exponential growth model with a stopping time at which &lt;span class="math"&gt;\(\Delta T\)&lt;/span&gt; becomes constant. It has parameters &lt;span class="math"&gt;\(\theta_{M4} = \Delta T_0, f, t_0, t_{stop}\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The evidence calculation is very computationally difficult for most algorithms, but I will be using the &lt;a href="http://arxiv.org/abs/0809.3437"&gt;MultiNest algorithm&lt;/a&gt; that is designed specifically for bayesian evidence calculation. There is a nice Python wrapper to the algorithm &lt;a href="https://github.com/JohannesBuchner/PyMultiNest"&gt;here&lt;/a&gt;. For any interested parties, I have a &lt;a href="https://github.com/kgullikson88/General/blob/a0803368154b18e4e051e35b77b1a2eb41e51dc1/Fitters.py#L947"&gt;wrapper&lt;/a&gt; to &lt;em&gt;that&lt;/em&gt; that makes this whole model comparison thing easier and a bit more "pythonic". I did all of this analysis in a ipython notebook &lt;a href="https://github.com/kgullikson88/Ipython_Notebooks/blob/master/Climate_Data_multinest.ipynb"&gt;here&lt;/a&gt;, and you can see how I use my wrapper there.&lt;/p&gt;
&lt;h1&gt;The Fits and Bayesian Evidence&lt;/h1&gt;
&lt;p&gt;Here is a visual representation of the four fits. The data is in blue, and I have removed the uncertainties for clarity. Check back above to remind yourself how big the errors are though! The red lines are 100 samples from the posterior probability function. Remember, the posterior probability function gives us what parameters are most compatible with the data so the spread in red lines tells you something about the range of reasonable parameters.&lt;/p&gt;
&lt;style type="text/css"&gt;
.floated_img
{
    float: left;
}
.section {
  width: 50%;
  height: 50%;
  border: solid 1px #000;
  display: inline-block;
  vertical-align: middle;
  position: relative;
}
.section img {
  position: absolute;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  margin: auto;
  max-height: 90%;
  max-width: 90%;
}
&lt;/style&gt;

&lt;table width="100%" border="0" cellspacing="0" cellpadding="0"&gt;
  &lt;tr&gt;
    &lt;td&gt;&lt;img src="Figures/Constant.png" width= "100%"  border="0"&gt;&lt;/td&gt;
    &lt;td&gt;&lt;img src="Figures/Polynomial.png" width= "100%"  border="0"&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;&lt;img src="Figures/ExpFit.png" width= "100%"  border="0"&gt;&lt;/td&gt;
    &lt;td&gt;&lt;img src="Figures/ExpFit_Stop.png" width= "100%"  border="0"&gt;&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;The constant model is very obviously bad and was chosen to be so to demonstrate how bayesian evidence works. The polynomial fit reproduces the data much better, but so does the exponential fit that has 3 fewer parameters. &lt;/p&gt;
&lt;p&gt;Let's take a look at the bayesian evidence for each of the three first models. Since the multinest algorithm numerically calculates the evidence, it has some uncertainty that I also quote. Also note that the values quoted here are actually &lt;em&gt;&lt;span class="math"&gt;\(log(evidence)\)&lt;/span&gt;&lt;/em&gt; rather than just the evidence (that makes it computationally more stable).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Constant model evidence: &lt;span class="math"&gt;\(34.11 \pm 0.02\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Polynomial model evidence: &lt;span class="math"&gt;\(55.01 \pm 0.01\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Exponential model evidence: &lt;span class="math"&gt;\(101.7 \pm 0.1\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So the evidence lines up very well with both the visual quality of the fits and Occam's razor: The constant model has only one parameter, but very poor predictive power. The polynomial model has high predictive power, but a very large parameter space. The exponential growth model has the best of both worlds, and has the highest evidence. &lt;/p&gt;
&lt;p&gt;So now that we know that the bayesian evidence gives results that line up with intuition, what does it say about the final model I have tested (exponential growth that has recently stopped)? The evidence for that model is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Exponential model with GW stop evidence: &lt;span class="math"&gt;\(100.76 \pm 0.06\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The evidence for the final model is just slightly smaller than for the exponential growth model. Now, the actual values are not as important as their &lt;em&gt;ratio&lt;/em&gt;, so lets take a look at the ratio of each model to every other model in the table below. I will convert to actual evidence instead of log(evidence) so that we can really compare how much the data favors one model over the other.&lt;/p&gt;
&lt;style type="text/css"&gt;
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}
.tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:keep-all;}
@media screen and (max-width: 767px) {.tg {width: auto !important;}.tg col {width: auto !important;}.tg-wrap {overflow-x: auto;-webkit-overflow-scrolling: touch;}}&lt;/style&gt;

&lt;div class="tg-wrap"&gt;&lt;table class="tg"&gt;
  &lt;col width="120"&gt;
  &lt;col width="120"&gt;
  &lt;col width="120"&gt;
  &lt;col width="120"&gt;
  &lt;col width="150"&gt;
  &lt;tr&gt;
    &lt;th class="tg-031e"&gt;&lt;/th&gt;
    &lt;th class="tg-031e"&gt;Constant&lt;/th&gt;
    &lt;th class="tg-031e"&gt;Polynomial&lt;/th&gt;
    &lt;th class="tg-031e"&gt;Exponential&lt;/th&gt;
    &lt;th class="tg-031e"&gt;Exponential-Stop&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class="tg-031e"&gt;Constant&lt;/td&gt;
    &lt;td class="tg-031e"&gt;1&lt;/td&gt;
    &lt;td class="tg-031e"&gt;&lt;/td&gt;
    &lt;td class="tg-031e"&gt;&lt;/td&gt;
    &lt;td class="tg-031e"&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class="tg-031e"&gt;Polynomial&lt;/td&gt;
    &lt;td class="tg-031e"&gt;&lt;span class="math"&gt;\(8 \times 10^{-10}\)&lt;/span&gt;&lt;/td&gt;
    &lt;td class="tg-031e"&gt;1&lt;/td&gt;
    &lt;td class="tg-031e"&gt;&lt;/td&gt;
    &lt;td class="tg-031e"&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class="tg-031e"&gt;Exponential&lt;/td&gt;
    &lt;td class="tg-031e"&gt;&lt;span class="math"&gt;\(4.5 \times 10^{-30}\)&lt;/span&gt;&lt;/td&gt;
    &lt;td class="tg-031e"&gt;&lt;span class="math"&gt;\(5 \times 10^{-21}\)&lt;/span&gt;&lt;/td&gt;
    &lt;td class="tg-031e"&gt;1&lt;/td&gt;
    &lt;td class="tg-031e"&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class="tg-031e"&gt;Exponential-Stop&lt;/td&gt;
    &lt;td class="tg-031e"&gt;&lt;span class="math"&gt;\(10^{-29}\)&lt;/span&gt;&lt;/td&gt;
    &lt;td class="tg-031e"&gt;&lt;span class="math"&gt;\(10^{-20}\)&lt;/span&gt;&lt;/td&gt;
    &lt;td class="tg-031e"&gt;&lt;span class="math"&gt;\(2.5 \pm 0.3\)&lt;/span&gt;&lt;/td&gt;
    &lt;td class="tg-031e"&gt;1&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;&lt;/div&gt;

&lt;p&gt;Clearly, the constant and polynomial models are terrible; the data supports the hypothesis of an exponential model by many orders of magnitude over either of them. The exponential and exponential-stop models are very comparable; the data favors the simpler model by a factor of &lt;span class="math"&gt;\(\sim 2.5\)&lt;/span&gt;, but that is not really enough of a difference to reject either model. What I can say is:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;"The data do not favor a model where global temperatures have stopped warming."&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;There is one final thing to look at: what year does the data suggest global warming stopped under that model? Here is a histogram of samples from the posterior probability function for that parameter:&lt;/p&gt;
&lt;p class="centeredImage"&gt;&lt;img src="Figures/GW_Stoptime.png"&gt;&lt;/p&gt;

&lt;p&gt;The model prefers very recent years, which means most of the predicted temperature anomalies are identical to the simple exponential model. In fact, many of the samples have the warming trend stopping &lt;em&gt;in the future&lt;/em&gt;, where &lt;strong&gt;all&lt;/strong&gt; of the model-predicted temperatures are the same as in the simpler model. If the warming trend had truly stopped, this model would have been able to pick when the trend stopped to within a few years. The fact that the posterior probability function is roughly flat for the last decade, coupled with the fact that the bayesian evidence does not favor the stopping model, tells me that it is a poor model for the data. &lt;/p&gt;
&lt;p&gt;Please stop saying that global warming has stopped, and feel free to send this to anyone who thinks it has!&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }
    
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); ";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="Model Comparison"></category><category term="Political"></category></entry></feed>