{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse the requirements file\n",
    "The previous notebook, 'PyPi_Metadata.ipynb', parsed the requirements out of every package on the pypi server. The output was a file that looks like this:\n",
    "\n",
    "```\n",
    "packages/astrodbkit-0.2.0\n",
    "\n",
    "packages/astrodendro-0.1.0\n",
    "aplpy\n",
    "astropy\n",
    "matplotlib\n",
    "numpy\n",
    "\n",
    "packages/astroid-1.4.4\n",
    "\n",
    "packages/astroimtools-0.1\n",
    "git+http://github.com/astropy/astropy.git#egg=astropy\n",
    "astropy-helpers\n",
    "cython>=0.23.4\n",
    "distribute==0.0\n",
    "matplotlib\n",
    "numpy\n",
    "```\n",
    "\n",
    "The packages start with the name of the python package, followed by the dependencies I was able to parse. Many of them have no dependencies; for now I will assume that is correct even though I know it is not true. Any package that programmatically defines the requirements in the setup.py, and which have no requirements files, are not found.\n",
    "\n",
    "The purpose of this notebook will largely just be to parse the output file into a pandas dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import numpy as np\n",
    "import requirements\n",
    "import xmlrpclib\n",
    "\n",
    "# I need this to separate the package name from its version\n",
    "client = xmlrpclib.ServerProxy('http://pypi.python.org/pypi')\n",
    "packages = client.list_packages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Parse the requirements for each package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datadict = defaultdict(list)\n",
    "with open('requirements.txt', 'r') as infile:\n",
    "    new_package = True\n",
    "    for line in infile:\n",
    "        if line.strip() == '':\n",
    "            new_package = True\n",
    "            #print(package_name)\n",
    "            if package_name not in datadict['package']:\n",
    "                datadict['package'].append(package_name)\n",
    "                datadict['requirement'].append(np.nan)\n",
    "            continue\n",
    "        \n",
    "        if new_package:\n",
    "            # If this is the case, the current line gives the name of the package\n",
    "            package_name = os.path.basename(line).strip()\n",
    "            new_package = False\n",
    "        else:\n",
    "            # This line gives a requirement for the current package\n",
    "            try:\n",
    "                for req in requirements.parse(line.strip()):\n",
    "                    datadict['package'].append(package_name)\n",
    "                    datadict['requirement'].append(req.name)\n",
    "            except ValueError:\n",
    "                pass\n",
    "                \n",
    "\n",
    "# Convert to dataframe\n",
    "df = pd.DataFrame(data=datadict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Get the base package name from the package string\n",
    "The package column of the dataframe currently contains the name of the package as well as the version string. I need to separate the two. For that, I will use the package list from pypi itself again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['package_name'] = np.nan\n",
    "df['package_version'] = np.nan\n",
    "for i, package in enumerate(packages):\n",
    "    if i % 100 == 0:\n",
    "        print('Package {}: {}'.format(i+1, package))\n",
    "    for release in client.package_releases(package):\n",
    "        pkg_str = '{}-{}'.format(package, release)\n",
    "        idx = df.loc[df.package == pkg_str].index\n",
    "        if len(idx) > 0:\n",
    "            df.loc[idx, 'package_name'] = package\n",
    "            df.loc[idx, 'package_version'] = release\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save to file\n",
    "df.to_csv('requirements.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base dependencies\n",
    "\n",
    "I have now parsed the formal dependencies for 20642 python packages. However, some of those dependencies themselves have dependencies. Let's go ahead and find the base dependency. I will find all of the requirements that each requirements itself has, and keep going until there are no new dependencies.\n",
    "\n",
    "## Difficulties:\n",
    "\n",
    "1. Cyclic dependencies: astropy requires wcs_axes, which itself requires astropy. Therefore a naive recursive solution will never end. I use a Tree class that keeps track of what has already been searched to avoid infinite loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Tree(object):\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.children = []\n",
    "        return\n",
    "\n",
    "    def __contains__(self, obj):\n",
    "        return obj == self.name or any([obj in c for c in self.children])\n",
    "    \n",
    "    def add(self, obj):\n",
    "        if not self.__contains__(obj):\n",
    "            self.children.append(Tree(obj))\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def get_base_requirements(self):\n",
    "        base = []\n",
    "        for child in self.children:\n",
    "            if len(child.children) == 0:\n",
    "                base.append(child.name)\n",
    "            else:\n",
    "                for b in [c.get_base_requirements() for c in child.children()]:\n",
    "                    base.extend(b)\n",
    "        return np.unique(base)\n",
    "    \n",
    "\n",
    "def get_requirements(package):\n",
    "    return df.loc[(df.package_name == package) & (df.requirement.notnull()), 'requirement'].values\n",
    "\n",
    "\n",
    "def get_dependency_tree(package, tree):\n",
    "    reqs = get_requirements(package)\n",
    "    for req in reqs:\n",
    "        #print(req)\n",
    "        flg = tree.add(req)\n",
    "        if not flg:\n",
    "            continue\n",
    "        tree = get_base_dependencies(req, tree)\n",
    "    return tree\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = '115wangpan'\n",
    "p = 'astroquery'\n",
    "get_dependency_tree(p, Tree(p)).get_base_requirements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datadict = defaultdict(list)\n",
    "for i, package in enumerate(df.package_name.unique()):\n",
    "    if i % 100 == 0:\n",
    "        print('Package {}: {}'.format(i+1, package))\n",
    "    try:\n",
    "        deptree = get_dependency_tree(package, Tree(package))\n",
    "    except:\n",
    "        print('Failure getting base dependencies for {}'.format(package))\n",
    "        raise ValueError\n",
    "    for dependency in deptree.get_base_requirements():\n",
    "        datadict['package_name'].append(package)\n",
    "        datadict['requirements'].append(dependency)\n",
    "\n",
    "base_df = pd.DataFrame(data=datadict)\n",
    "base_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_df.to_csv('base_requirements.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
